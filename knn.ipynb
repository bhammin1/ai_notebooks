{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k Nearest Neighbors and Model Evaluation\n",
    "\n",
    "In this programming assignment you will use k Nearest Neighbors (kNN) to build a \"model\" that will estimate the compressive strength of various types of concrete. This assignment has several objectives:\n",
    "\n",
    "1. Implement the kNN algorithm with k=9. Remember...the data + distance function is the model in kNN. In addition to asserts that unit test your code, you should \"test drive\" the model, showing output that a non-technical person could interpret.\n",
    "\n",
    "2. You are going to compare the kNN model above against the baseline model described in the course notes (the mean of the training set's target variable). You should use 10 fold cross validation and Mean Squared Error (MSE):\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum^n_i (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "as the evaluation metric (\"error\"). Refer to the course notes for the format your output should take. Don't forget a discussion of the results.\n",
    "\n",
    "3. use validation curves to tune a *hyperparameter* of the model. \n",
    "In this case, the hyperparameter is *k*, the number of neighbors. Don't forget a discussion of the results.\n",
    "\n",
    "4. evaluate the *generalization error* of the new model.\n",
    "Because you may have just created a new, better model, you need a sense of its generalization error, calculate that. Again, what would you like to see as output here? Refer to the course notes. Don't forget a discussion of the results. Did the new model do better than either model in Q2?\n",
    "\n",
    "5. pick one of the \"Choose Your Own Adventure\" options.\n",
    "\n",
    "Refer to the \"course notes\" for this module for most of this assignment.\n",
    "Anytime you just need test/train split, use fold index 0 for the test set and the remainder as the training set.\n",
    "Discuss any results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "The function `parse_data` loads the data from the specified file and returns a List of Lists. The outer List is the data set and each element (List) is a specific observation. Each value of an observation is for a particular measurement. This is what we mean by \"tidy\" data.\n",
    "\n",
    "The function also returns the *shuffled* data because the data might have been collected in a particular order that *might* bias training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Dict, Tuple, Callable\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [float(value) for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_data(\"concrete_compressive_strength.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[425.0, 106.3, 0.0, 151.4, 18.6, 936.0, 803.7, 3.0, 36.3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,030 observations and each observation has 8 measurements. The data dictionary for this data set tells us the definitions of the individual variables (columns/indices):\n",
    "\n",
    "| Index | Variable | Definition |\n",
    "|-------|----------|------------|\n",
    "| 0     | cement   | kg in a cubic meter mixture |\n",
    "| 1     | slag     | kg in a cubic meter mixture |\n",
    "| 2     | ash      | kg in a cubic meter mixture |\n",
    "| 3     | water    | kg in a cubic meter mixture |\n",
    "| 4     | superplasticizer | kg in a cubic meter mixture |\n",
    "| 5     | coarse aggregate | kg in a cubic meter mixture |\n",
    "| 6     | fine aggregate | kg in a cubic meter mixture |\n",
    "| 7     | age | days |\n",
    "| 8     | concrete compressive strength | MPa |\n",
    "\n",
    "The target (\"y\") variable is a Index 8, concrete compressive strength in (Mega?) [Pascals](https://en.wikipedia.org/wiki/Pascal_(unit))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\", \"y\", \"est_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Splits - n folds\n",
    "\n",
    "With n fold cross validation, we divide our data set into n subgroups called \"folds\" and then use those folds for training and testing. You pick n based on the size of your data set. If you have a small data set--100 observations--and you used n=10, each fold would only have 10 observations. That's probably too small. You want at least 30. At the other extreme, we generally don't use n > 10.\n",
    "\n",
    "With 1,030 observations, n = 10 is fine so we will have 10 folds.\n",
    "`create_folds` will take a list (xs) and split it into `n` equal folds with each fold containing one-tenth of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = create_folds(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always use one of the n folds as a test set (and, sometimes, one of the folds as a *pruning* set but not for kNN), and the remaining folds as a training set.\n",
    "We need a function that'll take our n folds and return the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the function to give us a train and test datasets where the test set is the fold at index 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = create_train_test(folds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"euclidean_dist\"></a>\n",
    "## euclidean_dist\n",
    "\n",
    "This function calculates the euclidean distance between a group of training data\n",
    "compared to a single point. \n",
    "\n",
    "\n",
    "* **data** List[List[float]]: list of data points with multiple numeric features\n",
    "* **query** List[float]: a single data point with multiple features\n",
    "\n",
    "\n",
    "**returns** List[float]: distances between each point in data to the query point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(data:List[List[float]],query:List[float])->List[float]:\n",
    "    dist = []\n",
    "    for rw in data:\n",
    "        if len(rw) != len(query):\n",
    "            print(\"The number of features between data and query doesn't match\")\n",
    "            return []\n",
    "        sum = 0\n",
    "        for col_index in range(len(rw) -1): #excluding making distance on label field\n",
    "            diff = rw[col_index] - query[col_index]\n",
    "            diff_squared = diff * diff\n",
    "            sum += diff_squared\n",
    "        diff_root = math.sqrt(sum)\n",
    "        dist.append(diff_root)\n",
    "    return dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features between data and query doesn't match\n"
     ]
    }
   ],
   "source": [
    "# data from the self check\n",
    "d_test = [[.23,.81, .5],[.42,.78,.7],[.64,.23,.8],[.87,.19,.12],[.76,.43,.34]]\n",
    "y_test = [.39, .63,.45]\n",
    "dists_test = euclidean_dist(d_test,y_test )\n",
    "dists_test\n",
    "\n",
    "# check function returns a list\n",
    "assert isinstance(dists_test, list)\n",
    "\n",
    "#check the number of distances returned is length of data\n",
    "assert len(dists_test)== len(d_test)\n",
    "\n",
    "#check all values are positive (from the power and the square in algo)\n",
    "for dist in dists_test:\n",
    "    assert dist > 0\n",
    "\n",
    "d_test2 = [[item[0]] for item in d_test]\n",
    "dists_test2 = euclidean_dist(d_test2,y_test )\n",
    "# check empty distance is returned if a mismatch in features\n",
    "assert dists_test2 == []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"find_top_k\"></a>\n",
    "## find_top_k\n",
    "\n",
    "Finds the indexes of the closests neighbors. The closest k indexes are retuned\n",
    "\n",
    "\n",
    "* **dists** List[float]: list of distances\n",
    "* **k** int: number of neighbors to find\n",
    "\n",
    "\n",
    "**returns** List[int]: indexes of closest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_k(dists: List[float], k:int)->List[int]:\n",
    "    dists_copy = deepcopy(dists)\n",
    "    closest_neighbors = []\n",
    "    while len(closest_neighbors) < k:\n",
    "        current_min = min(dists_copy)\n",
    "        neighbor = dists.index(current_min)\n",
    "        closest_neighbors.append(neighbor)\n",
    "        \n",
    "        dists_copy.remove(current_min) # remove from list to find next closest neighbor\n",
    "\n",
    "    return closest_neighbors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_test = [9.1,2.2, 5.3, 6.5, 7.6, 1.3, 0.4, 8.6]\n",
    "k_test = 3\n",
    "len_dists = len(dists_test)\n",
    "n = find_top_k(dists_test, k_test)\n",
    "\n",
    "# check the number of items returned matches k\n",
    "assert len(n) == k_test\n",
    "\n",
    "#check only indexes are returned. No distances/floats returned\n",
    "for item in n:\n",
    "    assert isinstance(item, int)\n",
    "\n",
    "# Check that the correct indexes are returned\n",
    "assert n == [6, 5, 1]\n",
    "\n",
    "# check length of distances stays the same\n",
    "assert len(dists_test) == len_dists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"knn\"></a>\n",
    "## knn\n",
    "\n",
    "- Returns a list of predictions for each query.\n",
    "- The prediction is from taking the average value of the\n",
    "k nearest neighbors. \n",
    "- The neareness measure comes from the euclidean distance\n",
    "\n",
    "\n",
    "* **data** List[List[float]]: list of data points to measure against the query points\n",
    "* **queries** List[List[float]]:list of data points to make predictions of\n",
    "* **k** int:number of neighbors in aggregate to make prediction\n",
    "\n",
    "\n",
    "**returns** List[float]: returns a list of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data:List[List[float]], queries:List[List[float]], k:int)-> List[float]:\n",
    "    preds = []\n",
    "\n",
    "    for query in queries:\n",
    "        dists = euclidean_dist(data,query) # get distances\n",
    "        \n",
    "        neighbors = find_top_k(dists, k) # find closest neighbors\n",
    "        \n",
    "        label_index = len(query) - 1\n",
    "        labels = [data[n_index][label_index] for n_index in neighbors] # getting values of neighbors\n",
    "        \n",
    "        est_y = round((sum(labels)/ k), 2) # make prediction for query point\n",
    "        preds.append(est_y) # add column\n",
    "    \n",
    "    return preds\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test =[[1,2,3],[3,3,3],[4,4,4],[4,5,6],[5,6,7],[4,4,4]]\n",
    "queries_test= [[4,5,5],[2,2,2]]\n",
    "data_len = len(data_test)\n",
    "queries_len = len(queries_test)\n",
    "labels_test = knn(data_test, queries_test, 2)\n",
    "labels_test\n",
    "\n",
    "#check number of prediction is same number of queries\n",
    "assert len(labels_test) == len(queries_test)\n",
    "\n",
    "#check predictions are floats. They are averages of labels\n",
    "for label in labels_test:\n",
    "    assert isinstance(label, float)\n",
    "\n",
    "#check no changes in size happens to the data or query lists\n",
    "assert len(data_test) == data_len and len(queries_test) == queries_len\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"null_model\"></a>\n",
    "## null_model\n",
    "\n",
    "- Returns a list of predictions\n",
    "- All prediction values will be the average label in the data set\n",
    "\n",
    "\n",
    "* **data** List[List[float]]: list of data points to measure against the query points\n",
    "* **queries** List[List[float]]:list of data points to make predictions of\n",
    "\n",
    "**returns** List[float]: returns a list of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_model(data: List[List[float]], queries:List[List[float]])-> List[float]:\n",
    "    data_labels = [rw[-1] for rw in data]\n",
    "    avg = round((sum(data_labels)/ len(data)), 2) \n",
    "\n",
    "    preds = [avg for query in queries]\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test =[[1,2,3],[3,3,3],[4,4,4],[4,5,6],[5,6,7],[4,4,4]]\n",
    "queries_test= [[4,5,5],[2,2,2]]\n",
    "\n",
    "preds_test = null_model(data_test, queries_test)\n",
    "\n",
    "#check number of predictions matches number of queries\n",
    "assert len(preds_test) == len(queries_test)\n",
    "\n",
    "# check pred is the same value\n",
    "assert preds_test[0] == preds_test[1]\n",
    "\n",
    "#check pred is a float. Should be a label value not an index\n",
    "assert isinstance(preds_test[0], float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mse\"></a>\n",
    "## mse\n",
    "\n",
    "- Returns the mean squared error of the predictions\n",
    "- This function first finds the error between the prediction and actual value\n",
    "- Then squares that value. \n",
    "- Then the average is take of the errors. \n",
    "- A low error rate is best. The closer to zero the better. \n",
    "\n",
    "* **labels** List[float]: list of true labels/the actual value\n",
    "* **preds** List[float]:list predicted values\n",
    "\n",
    "**returns** float: returns the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(labels:List[float], preds:List[float])-> float:\n",
    "    sum = 0\n",
    "    for index in range(len(labels)):\n",
    "        diff = labels[index] - preds[index]\n",
    "        diff_squared = diff * diff\n",
    "        sum += diff_squared\n",
    "    mse_val = round((sum / len(labels)),4)\n",
    "    return mse_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from self check MSE questions\n",
    "y = [3.78,4.82,2.83,2.76,3.48]\n",
    "y_hat =[3.32,5.21,2.97,2.37,3.29]\n",
    "test_mse= mse(y, y_hat)\n",
    "\n",
    "# check only one value returned. Not a list of errors\n",
    "assert isinstance(test_mse, float)\n",
    "\n",
    "# check the value is greater than zero. Zero means the is no errors aka perfect model\n",
    "assert test_mse > 0\n",
    "\n",
    "#check the mean squared error is the expected value\n",
    "assert test_mse == .1143"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"print_errors\"></a>\n",
    "## print_errors\n",
    "\n",
    "- print error function returns no value, but instead prints the errors like in the documentation\n",
    "- An error rate per fold is printed\n",
    "- At the end the average error rate is printed\n",
    "\n",
    "* **error** List[float]: list of errors per fold\n",
    "* **preds** str: name of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_errors(errors:List[float], model:str):\n",
    "    print(\"Error Rate for model\", model)\n",
    "    for i in range(10):\n",
    "        fold_num = i +1\n",
    "        print(\"Fold\",fold_num, \"error rate:\", errors[i] )\n",
    "    # find average\n",
    "    avg = sum(errors)/ len(errors)\n",
    "    print(\"Mean=\", avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no unit test because this function is only for displaying output\n",
    "# nothing is returned to a value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plot_val_curves\"></a>\n",
    "## plot_val_curves\n",
    "\n",
    "- This function returns no value, but instead prints a validation curve\n",
    "- The validation curves plots the error rate for both the training and test data\n",
    "- The test curve with the lowest error rate is the optimal hyperparameter\n",
    "\n",
    "* **x** List[int]: list of k values, the hyperparameters that were tuned\n",
    "* **test** List[float]: list of test errors\n",
    "* **train** List[float]: list of training errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_val_curves(x:List[int], test:List[float], train:List[float]):\n",
    "    plt.plot(x, test, label =\"test\")\n",
    "    plt.plot(x, train, label=\"train\")\n",
    "    plt.xlabel(\"K Values\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Validation Curves\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"z_score\"></a>\n",
    "## z_score\n",
    "\n",
    "- Normalizes the data but transforming each column to be the z score\n",
    "- All columns in the query data set are transformed except for the label column\n",
    "- The label column is always the last column\n",
    "- Z = X- Mean / Standard Deviation\n",
    "\n",
    "* **data** List[List[float]]: list of training data. Data used to calc mean and standard deviation\n",
    "* **query** List[List[float]]: data set to normalize\n",
    "\n",
    "**returns** List[List[float]]: normalized data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(data:List[List[float]], query:List[List[float]])-> List[List[float]]:\n",
    "    means = []\n",
    "    st_devs = []\n",
    "    norm = deepcopy(query)\n",
    "\n",
    "    for feature in range(len(data[0]) -1): # get data mean and stdev\n",
    "        col = [row[feature] for row in data]\n",
    "        mean = sum(col)/ len(col)\n",
    "        diff = [ pow(( x- mean), 2) for x in col ]\n",
    "        diff_sum = sum(diff)\n",
    "        st_dev = pow(diff_sum/ len(col),.5)\n",
    "        \n",
    "        means.append(mean)\n",
    "        st_devs.append(st_dev)\n",
    "  \n",
    "    for rw in range(len(query)):\n",
    "        for col in range(len(query[rw])-1):\n",
    "            z = (query[rw][col] - means[col])/ (st_devs[col])\n",
    "            norm[rw][col] = round(z, 4) # normalize data\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1,2,3], [2,2,2], [1,6,4]]\n",
    "y = [[4,5,6],[4,3,6]]\n",
    "norm_y = z_score(x, y)\n",
    "\n",
    "#check the original data set didnt get updated\n",
    "assert y != norm_y\n",
    "\n",
    "#check that the last row, label column, matches\n",
    "# checking we did not normalize the label column\n",
    "assert [ rw[-1] for rw in y] == [ rw[-1] for rw in norm_y]\n",
    "\n",
    "#check that all data is present\n",
    "assert len(y) == len(norm_y)\n",
    "assert len(y[0]) == len(norm_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "Answer the questions above in the space provided below, adding cells as you need to.\n",
    "Put everything in the helper functions and document them.\n",
    "Document everything (what you're doing and why).\n",
    "If you're not sure what format the output should take, refer to the course notes and what they do for that particular topic/algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: kNN\n",
    "\n",
    "Implement k Nearest Neighbors with k = 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2     3     4     5     6     7     y est_y\n",
      " 425.0 106.3   0.0 151.4  18.6 936.0 803.7   3.0  36.3 57.28\n",
      " 379.5 151.2   0.0 153.9  15.91134.3 605.0  56.0  54.9 54.36\n",
      " 213.7  98.1  24.5 181.7   6.91065.8 785.4 100.0  53.9  46.2\n",
      " 194.7   0.0 100.5 170.2   7.5 998.0 901.8 100.0 44.28 42.67\n",
      " 425.0 106.3   0.0 151.4  18.6 936.0 803.7  28.0  61.8 62.87\n",
      " 213.5   0.0 174.2 154.6  11.71052.3 775.5  56.0 51.43  42.0\n",
      " 213.5   0.0 174.2 159.2  11.71043.6 771.9   3.0 15.61 29.15\n",
      " 303.6 139.9   0.0 213.5   6.2 895.5 722.5  28.0 33.42 43.51\n",
      " 213.5   0.0 174.2 154.6  11.71052.3 775.5  28.0 45.94 33.33\n",
      " 181.4   0.0 167.0 169.6   7.61055.6 777.8 100.0 45.37 42.81\n",
      " 198.6 132.4   0.0 192.0   0.0 978.4 825.5   7.0 14.64 16.59\n",
      " 153.0 102.0   0.0 192.0   0.0 888.0 943.1  28.0 17.96 14.57\n",
      " 297.8 137.2 106.9 201.3   6.0 878.4 655.3  28.0 53.52 42.59\n",
      " 230.0   0.0 118.3 195.5   4.61029.4 758.6   3.0 10.03 21.05\n",
      " 388.6  97.1   0.0 157.9  12.1 852.1 925.7  28.0  50.7 49.63\n",
      " 116.0 173.0   0.0 192.0   0.0 909.8 891.9   7.0 10.09 15.92\n",
      " 436.0   0.0   0.0 218.0   0.0 838.4 719.7  28.0 23.85 41.21\n",
      " 356.0   0.0 142.0 193.0  11.0 801.0 778.0  28.0 40.87 35.55\n",
      " 102.0 153.0   0.0 192.0   0.0 887.0 942.0   7.0  7.68  16.5\n",
      " 491.0  26.0 123.0 210.0   3.9 882.0 699.0  28.0 55.55 42.73\n",
      " 286.3 200.9   0.0 144.7  11.21004.6 803.7   3.0  24.4 49.73\n",
      " 203.5 305.3   0.0 203.5   0.0 963.4 630.0   3.0  9.56 32.98\n",
      " 154.0 174.0 185.0 228.0   7.0 845.0 612.0  28.0 24.34 30.97\n",
      " 425.0 106.3   0.0 153.5  16.5 852.1 887.1  91.0  65.2 62.42\n",
      " 238.0   0.0   0.0 186.0   0.01119.0 789.0   7.0 12.05 15.45\n",
      " 333.0   0.0   0.0 192.0   0.0 931.2 842.6  90.0 41.68 32.74\n",
      " 374.3   0.0   0.0 190.2   6.71013.2 730.4  28.0 39.06 37.14\n",
      " 309.9 142.8 111.2 167.8  22.1 913.9 651.2  28.0 38.22  43.3\n",
      " 304.0 140.0   0.0 214.0   6.0 895.0 722.0  28.0 33.42 43.51\n",
      " 254.0   0.0   0.0 198.0   0.0 968.0 863.0 365.0 29.79 36.21\n",
      " 313.0   0.0   0.0 178.0   8.01000.0 822.0  28.0  25.1 29.16\n",
      " 362.6 189.0   0.0 164.9  11.6 944.7 755.8   3.0  35.3 49.57\n",
      " 310.0   0.0   0.0 192.0   0.0 970.0 850.0   7.0 14.99 19.48\n",
      " 322.0   0.0   0.0 203.0   0.0 974.0 800.0  28.0 25.18 29.83\n",
      " 173.8  93.4 159.9 172.3   9.71007.2 746.6  28.0 37.81 36.16\n",
      " 491.0  26.0 123.0 201.0   3.9 822.0 699.0  56.0 61.86 42.74\n",
      " 424.0  22.0 132.0 168.0   8.9 822.0 750.0  56.0 74.36 44.27\n",
      " 475.0 118.8   0.0 181.1   8.9 852.1 781.5  28.0  68.3 60.21\n",
      " 212.0   0.0 124.8 159.0   7.81085.4 799.5  14.0 31.35 22.48\n",
      " 157.0 236.0   0.0 192.0   0.0 935.4 781.2  90.0 43.38 31.03\n",
      " 250.0   0.0  95.7 187.4   5.5 956.9 861.2  14.0 24.92 20.51\n",
      " 321.0 164.0   0.0 190.0   5.0 870.0 774.0  28.0 57.21 51.17\n",
      " 212.0 141.3   0.0 203.5   0.0 973.4 750.0   7.0 15.03 20.32\n",
      " 540.0   0.0   0.0 173.0   0.01125.0 613.0 180.0 71.62 59.07\n",
      " 158.0   0.0 195.0 220.0  11.0 898.0 713.0  28.0  8.54 15.16\n",
      " 362.6 189.0   0.0 164.9  11.6 944.7 755.8   3.0  35.3 49.57\n",
      " 146.0 230.0   0.0 202.0   3.0 827.0 872.0  28.0 33.06 28.47\n",
      " 375.0   0.0   0.0 186.0   0.01038.0 758.0  28.0 38.21 32.04\n",
      " 424.0  22.0 132.0 178.0   8.5 822.0 750.0   7.0  39.0 44.27\n",
      " 168.9  42.2 124.3 158.3  10.81080.8 796.2  56.0 39.15 33.85\n",
      " 295.7   0.0  95.6 171.5   8.9 955.1 859.2  14.0 35.23  35.2\n",
      " 480.0   0.0   0.0 192.0   0.0 936.0 721.0   3.0 24.39 41.21\n",
      " 102.0 153.0   0.0 192.0   0.0 887.0 942.0   3.0  4.57  15.9\n",
      " 160.0 188.0 146.0 203.0  11.0 829.0 710.0  28.0 32.84 32.08\n",
      " 148.5 139.4 108.6 192.7   6.1 892.4 780.0  28.0  23.7 30.87\n",
      " 250.0   0.0  95.7 191.8   5.3 948.9 857.2  28.0 27.22  25.8\n",
      " 289.0   0.0   0.0 192.0   0.0 913.2 895.3   3.0 11.65  15.5\n",
      " 183.9 122.6   0.0 203.5   0.0 959.2 800.0   3.0   4.9 16.59\n",
      " 286.3 200.9   0.0 144.7  11.21004.6 803.7   7.0  38.0 49.73\n",
      " 233.8   0.0  94.6 197.9   4.6 947.0 852.2  28.0 22.84 23.87\n",
      " 425.0 106.3   0.0 153.5  16.5 852.1 887.1   3.0  33.4 51.06\n",
      " 133.0 210.0   0.0 196.0   3.0 949.0 795.0  28.0 31.03 20.54\n",
      " 165.0 128.5 132.1 175.1   8.11005.8 746.6   3.0 19.42 30.82\n",
      " 186.2 124.1   0.0 185.7   0.01083.4 764.3   7.0   8.0 23.67\n",
      " 289.0 133.7   0.0 194.9   5.5 924.1 760.1  28.0 46.25  47.6\n",
      " 213.5   0.0 174.2 154.6  11.71052.3 775.5   3.0 17.37 29.15\n",
      " 182.0  45.2 122.0 170.2   8.21059.4 780.7 100.0 48.67  45.3\n",
      " 139.6 209.4   0.0 192.0   0.01047.0 806.9   3.0  8.06 23.52\n",
      " 186.2 124.1   0.0 185.7   0.01083.4 764.3  28.0  17.6 25.07\n",
      " 133.0 200.0   0.0 192.0   0.0 927.4 839.2   3.0  6.88 15.45\n",
      " 387.0  20.0  94.0 157.0  13.9 938.0 845.0   7.0  45.9 39.23\n",
      " 446.0  24.0  79.0 162.0  11.6 967.0 712.0  28.0 57.03 36.26\n",
      " 255.0   0.0   0.0 192.0   0.0 889.8 945.0  28.0 18.75 17.09\n",
      " 203.5 305.3   0.0 203.5   0.0 963.4 630.0   7.0 19.54 32.98\n",
      " 500.0   0.0   0.0 200.0   0.01125.0 613.0  14.0 36.94 37.85\n",
      " 260.0 101.0  78.0 171.0  10.0 936.0 763.0  28.0 49.77 37.81\n",
      " 167.0  75.4 167.0 164.0   7.91007.3 770.1  14.0  32.9 33.23\n",
      " 212.0   0.0 124.8 159.0   7.81085.4 799.5  56.0 45.08 32.37\n",
      " 331.0   0.0   0.0 192.0   0.0 978.0 825.0   7.0 16.26 24.84\n",
      " 142.0 167.0 130.0 174.0  11.0 883.0 785.0  28.0 44.61 30.97\n",
      " 385.0   0.0 136.0 158.0  20.0 903.0 768.0  28.0 55.55 45.78\n",
      " 212.1   0.0 121.6 180.3   5.71057.6 779.3 100.0 39.61 40.77\n",
      " 146.0 173.0   0.0 182.0   3.0 986.0 817.0  28.0 23.74 23.97\n",
      " 277.0   0.0   0.0 191.0   0.0 968.0 856.0 360.0  33.7 36.21\n",
      " 178.0 129.8 118.6 179.9   3.61007.3 746.8  56.0 48.59 42.37\n",
      " 252.3   0.0  98.8 146.3  14.2 987.8 889.0  14.0 42.29 30.83\n",
      " 424.0  22.0 132.0 168.0   8.9 822.0 750.0  28.0  72.1 44.27\n",
      " 475.0   0.0   0.0 228.0   0.0 932.0 594.0  90.0 42.23 42.63\n",
      " 491.0  26.0 123.0 210.0   3.9 882.0 699.0  56.0 59.59 44.34\n",
      " 500.0   0.0   0.0 140.0   4.0 966.0 853.0  28.0 67.57 58.74\n",
      " 145.0 116.0 119.0 184.0   5.7 833.0 880.0  28.0 29.16 28.88\n",
      " 284.0  15.0 141.0 179.0   5.5 842.0 801.0  56.0 44.52 33.71\n",
      " 275.1   0.0 121.4 159.5   9.91053.6 777.5   3.0  23.8 25.82\n",
      " 141.3 212.0   0.0 203.5   0.0 971.8 748.5   3.0  4.83 19.54\n",
      " 355.0  19.0  97.0 145.0  13.1 967.0 871.0  28.0 44.03 40.07\n",
      " 331.0   0.0   0.0 192.0   0.01025.0 821.0   3.0 14.31  18.9\n",
      " 116.0 173.0   0.0 192.0   0.0 909.8 891.9  28.0 22.35 17.85\n",
      " 236.0 157.0   0.0 192.0   0.0 972.6 749.1  28.0 32.88 25.21\n",
      " 531.3   0.0   0.0 141.8  28.2 852.1 893.7  56.0  58.8 53.55\n",
      " 276.0 116.0  90.0 180.0   9.0 870.0 768.0  28.0 44.28  37.6\n",
      " 165.0   0.0 143.6 163.8   0.01005.6 900.9 100.0 37.96 37.96\n",
      " 213.7   0.0 174.7 154.8  10.21053.5 776.4  56.0 46.64  42.0\n",
      " 297.2   0.0 117.5 174.8   9.51022.8 753.5   3.0 21.91  30.2\n"
     ]
    }
   ],
   "source": [
    "train, test = create_train_test(folds, 0)\n",
    "preds_knn9 = knn(train, test, 9)\n",
    "\n",
    "frmt = \"{:>6}\"*10 # to print output nicely \n",
    "print(frmt.format(*cols)) #print out col names\n",
    "for rw in range(len(test)):\n",
    "    rw_est = deepcopy(test[rw])\n",
    "    rw_est.append(preds_knn9[rw])\n",
    "    print(frmt.format(*rw_est))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Discussion\n",
    "- Problem 1 only provides predictions of the y column using the 9 nearests neighbors\n",
    "- Since no metrics were requested for this problem, we can't make too many assumptions about the data\n",
    "- Just by skimming the data, it looks like some predictions are very close to the actual value and others are very off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Evaluation vs. The Mean\n",
    "\n",
    "Using Mean Squared Error (MSE) as your evaluation metric, evaluate your implement above and the Null model, the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate for model 9 Nearest Neighbors\n",
      "Fold 1 error rate: 107.9585\n",
      "Fold 2 error rate: 118.0468\n",
      "Fold 3 error rate: 61.9127\n",
      "Fold 4 error rate: 69.5383\n",
      "Fold 5 error rate: 85.123\n",
      "Fold 6 error rate: 84.0148\n",
      "Fold 7 error rate: 82.8341\n",
      "Fold 8 error rate: 83.9085\n",
      "Fold 9 error rate: 82.3116\n",
      "Fold 10 error rate: 125.0381\n",
      "Mean= 90.06864\n",
      "\n",
      "\n",
      "Error Rate for model Null\n",
      "Fold 1 error rate: 299.9075\n",
      "Fold 2 error rate: 282.2684\n",
      "Fold 3 error rate: 281.579\n",
      "Fold 4 error rate: 254.0969\n",
      "Fold 5 error rate: 232.5995\n",
      "Fold 6 error rate: 259.3946\n",
      "Fold 7 error rate: 292.8486\n",
      "Fold 8 error rate: 345.4663\n",
      "Fold 9 error rate: 229.8771\n",
      "Fold 10 error rate: 313.2853\n",
      "Mean= 279.13232000000005\n"
     ]
    }
   ],
   "source": [
    "# get test labels\n",
    "null_errors = []\n",
    "knn9_errors =[]\n",
    "\n",
    "for i in range(10):\n",
    "    train, test = create_train_test(folds, i)\n",
    "    test_labels = [row[8] for row in test]\n",
    "    # get the null model\n",
    "    preds_null = null_model(train, test)\n",
    "    #get 9NN\n",
    "    preds_9nn = knn(train, test, 9)\n",
    "\n",
    "    # compare the results\n",
    "    null_mse = mse(test_labels, preds_null)\n",
    "    knn9_mse = mse(test_labels, preds_9nn)\n",
    "    null_errors.append(null_mse)\n",
    "    knn9_errors.append(knn9_mse)\n",
    "print_errors(knn9_errors, \"9 Nearest Neighbors\")\n",
    "print(\"\\n\")\n",
    "print_errors(null_errors, \"Null\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Discussion\n",
    "- This problem compares the 9NN model to the Null Model\n",
    "- Overall, the 9NN model had better performance than the Null model. \n",
    "- The 9NN model had the lowest mean squared error. Although, the error rate is still pretty high\n",
    "- The Null model had very high error rate on all folds. This is because all predictions are the same value\n",
    "- Both models had variation of error rate between folds. No fold had the same error rate for either model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Hyperparameter Tuning\n",
    "\n",
    "Tune the value of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = [1,2,3,4,5,6,7,8,9]\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "train, test = create_train_test(folds, 0)\n",
    "test_labels = [row[8] for row in test]\n",
    "train_labels = [row[8] for row in train]\n",
    "\n",
    "for i in range(len(params)):\n",
    "    # call KNN\n",
    "    train_pred = knn(train, train, params[i])\n",
    "    test_pred =knn(train, test, params[i])\n",
    "    # evaluate\n",
    "    train_mse = mse(train_labels, train_pred)\n",
    "    test_mse = mse(test_labels, test_pred)\n",
    "    train_errors.append(train_mse)\n",
    "    test_errors.append(test_mse)\n",
    "\n",
    "plot_val_curves(params, test_errors, train_errors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 Discussion\n",
    "- Tuning was done by creating a validation curve. \n",
    "- The curve plotted the error rate of the training and the testing data sets separately\n",
    "- The Value of K with the lowest error for the test set was 3.\n",
    "- When the value of k was 1 for the training set, the error rate was zero, as expected. This is because it is predicting off of the actual value. The K=1 for the training set is not really a neighbor\n",
    "- The test error rate is significantly higher than the training error rate. Adding more data could help improve this model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Generalization Error\n",
    "\n",
    "Analyze and discuss the generalization error of your model with the value of k from Problem 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate for model 3 Nearest Neighbors\n",
      "Fold 1 error rate: 98.0986\n",
      "Fold 2 error rate: 76.3839\n",
      "Fold 3 error rate: 59.7684\n",
      "Fold 4 error rate: 49.9689\n",
      "Fold 5 error rate: 76.0549\n",
      "Fold 6 error rate: 79.9068\n",
      "Fold 7 error rate: 71.5664\n",
      "Fold 8 error rate: 79.7444\n",
      "Fold 9 error rate: 65.082\n",
      "Fold 10 error rate: 83.5817\n",
      "Mean= 74.01559999999999\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(10):\n",
    "    train, test = create_train_test(folds, i)\n",
    "    test_labels = [row[8] for row in test]\n",
    "\n",
    "    knn_preds = knn(train, test, 3) # using the optimal param from prev problem\n",
    "    error_rate = mse(test_labels, knn_preds)\n",
    "    errors.append(error_rate)\n",
    "print_errors(errors, \"3 Nearest Neighbors\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 Discussion\n",
    "- The generalization error gives us insight on how well our model can make predictions with unknown data\n",
    "- The error rate collected is only based on making predictions of the test set\n",
    "- Compared the 9NN and the Null mode, the 3NN performed much better. 3NN had the lowest error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Choose your own adventure\n",
    "\n",
    "You have three options for the next part:\n",
    "\n",
    "1. You can implement mean normalization (also called \"z-score standardization\") of the *features*; do not normalize the target, y. See if this improves the generalization error of your model (middle).\n",
    "\n",
    "2. You can implement *learning curves* to see if more data would likely improve your model (easiest).\n",
    "\n",
    "3. You can implement *weighted* kNN and use the real valued GA to choose the weights. weighted kNN assigns a weight to each item in the Euclidean distance calculation. For two points, j and k:\n",
    "$$\\sqrt{\\sum w_i (x^k_i - x^j_i)^2}$$\n",
    "\n",
    "You can think of normal Euclidean distance as the case where $w_i = 1$ for all features  (ambitious, but fun...you need to start EARLY because it takes a really long time to run).\n",
    "\n",
    "The easier the adventure the more correct it must be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate for model 3 Nearest Neighbors\n",
      "Fold 1 error rate: 104.8352\n",
      "Fold 2 error rate: 63.8911\n",
      "Fold 3 error rate: 59.804\n",
      "Fold 4 error rate: 55.7595\n",
      "Fold 5 error rate: 65.5548\n",
      "Fold 6 error rate: 76.7593\n",
      "Fold 7 error rate: 61.9933\n",
      "Fold 8 error rate: 75.4078\n",
      "Fold 9 error rate: 72.4915\n",
      "Fold 10 error rate: 89.8082\n",
      "Mean= 72.63046999999999\n"
     ]
    }
   ],
   "source": [
    "# Z Score Normalization\n",
    "errors = []\n",
    "for i in range(10):\n",
    "    train, test = create_train_test(folds, i)\n",
    "    test_new = z_score(train, test)\n",
    "    train_new =  z_score(train, train)\n",
    "    test_labels = [row[8] for row in test]\n",
    "\n",
    "    knn_preds = knn(train_new, test_new, 3) # using the optimal param from prev problem\n",
    "    error_rate = mse(test_labels, knn_preds)\n",
    "    errors.append(error_rate)\n",
    "print_errors(errors, \"3 Nearest Neighbors\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 Discussion\n",
    "- Normalizing the data did improve my model a little bit. \n",
    "- The previous 3NN without normalization had an average error of 74.0 and my 3NN normalized had an error rate of 72.6\n",
    "- My understanding of normalizing the data is that you use the training datas mean and standard deviation in the z score formula when transforming both the test and training set, but maybe that is not correct. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "- I didn't have difficulties implementing any of the logic for KNN or the metrics\n",
    "- But I wasn't 100% sure about the formatting of the output. I tried following the course notes provided, but it still wasn't clear to me the format for some of the problems like problem 1 and 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "en605645",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e906c7fbe804ec0c103892f23dd17a311766537948dcf2ae45407952f88d8394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
